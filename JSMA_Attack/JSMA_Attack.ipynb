{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82828172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48774207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobian(model, image):\n",
    "    \"\"\" Compute the Jacobian matrix of the model output with respect to the input image. \"\"\"\n",
    "\n",
    "    image.requires_grad = True\n",
    "    output = torch.sigmoid(model(image.unsqueeze(0)))  # Forward pass\n",
    "    grad_outputs = torch.ones_like(output.squeeze(0))  # Same shape as y\n",
    "    element_wise_grad = torch.autograd.grad(output.squeeze(0), image, grad_outputs=grad_outputs)[0]\n",
    "    return element_wise_grad\n",
    "    \n",
    "def saliency_map(jacobian, target_label):\n",
    "    \"\"\" Compute the saliency map to determine which pixels to perturb. \"\"\"\n",
    "    # Compute impact of modifying each pixel\n",
    "    target_grad = jacobian * target_label  # Positive if it pushes towards target class    \n",
    "    return target_grad  # Saliency scores\n",
    "\n",
    "def jsma_attack(model, image, target_label, epsilon, alpha):\n",
    "    \"\"\"\n",
    "    Performs a JSMA attack with invisible perturbations on a binary segmentation model.\n",
    "    \n",
    "    Args:\n",
    "        model: The PyTorch model.\n",
    "        image: The input image (tensor of shape [C, H, W]).\n",
    "        target_label: The desired segmentation output (tensor of shape [H, W]).\n",
    "        initial_alpha: The initial perturbation step size.\n",
    "        epsilon: Maximum perturbation magnitude.\n",
    "    \n",
    "    Returns:\n",
    "        The adversarial image.\n",
    "    \"\"\"\n",
    "    adversarial = image.clone().detach()\n",
    "    decay_factor = 0.8\n",
    "    acc = 0\n",
    "    accs = torch.zeros(1000)\n",
    "    itr = 0\n",
    "    while (acc < 0.9):\n",
    "        jacobian = compute_jacobian(model, adversarial)  # Compute Jacobian\n",
    "        saliency = saliency_map(jacobian, target_label)  # Compute saliency\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            adversarial = adversarial + alpha * saliency.sign()\n",
    "            \n",
    "            adversarial = torch.max(torch.min(adversarial, image + epsilon), image - epsilon)\n",
    "            adversarial = torch.clamp(adversarial, 0, 1)\n",
    "\n",
    "\n",
    "        # Check if misclassification occurs\n",
    "        pred = model(adversarial.unsqueeze(0))\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred = (pred > 0.5).float()\n",
    "        acc = ((pred == target_label).sum()) / torch.numel(target_label)\n",
    "        \n",
    "        #print(f\"iter {itr} acc: {acc}\")\n",
    "        \n",
    "        accs[itr] = acc\n",
    "        if itr > 0 and accs[itr] <= accs[itr-1]:  \n",
    "            break\n",
    "        itr += 1\n",
    "        \n",
    "        alpha *= decay_factor\n",
    "    return adversarial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the image for the targeted class \n",
    "image_path = \"./ball.jpeg\"  # Change to your image path\n",
    "image = Image.open(image_path).convert(\"L\")\n",
    "\n",
    "\n",
    "# Define transformations: Resize, Convert to Tensor, Normalize\n",
    "threshold = 100  # Define the threshold\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "    transforms.ToTensor(),  # Converts image to [0, 1]\n",
    "    transforms.Lambda(lambda x: (x < threshold / 255).float())  # Binarization\n",
    "])\n",
    "# Apply transformations\n",
    "image_tensor = transform(image)\n",
    "print(image_tensor.unique())\n",
    "plt.imshow(image_tensor.permute(1,2,0).numpy(), cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34588754",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize=(20, 30))\n",
    "val_batch = next(itertools.islice(iter(val_loader), 1, None))\n",
    "for i in range(4):\n",
    "    image, target = val_batch[0][i], val_batch[1][i]\n",
    "\n",
    "    model.eval()  # Set to evaluation mod\n",
    "\n",
    "    adv_img = jsma_attack(model, image, image_tensor,0.062, 4/255)\n",
    "\n",
    "    Adv_pred = torch.sigmoid(model(adv_img.unsqueeze(0)))\n",
    "    Adv_pred = (Adv_pred > 0.5).float()\n",
    "    \n",
    "    pred = torch.sigmoid(model(val_batch[0][i].unsqueeze(0)))\n",
    "    pred = (pred > 0.5).float()\n",
    "    \n",
    "    axes[i,0].imshow(image.squeeze(0).permute(1,2,0).detach().cpu().numpy())\n",
    "    axes[i,0].set_title(\"original_image\")\n",
    "    axes[i,1].imshow(pred.squeeze(0).permute(1,2,0).detach().cpu().numpy(), cmap = \"gray\")\n",
    "    axes[i,1].set_title(\"pred\")\n",
    "    axes[i,2].imshow(adv_img.permute(1,2,0).detach().cpu().numpy())\n",
    "    axes[i,2].set_title(\"adv_image\")\n",
    "    axes[i,3].imshow(Adv_pred.squeeze(0).permute(1,2,0).detach().cpu().numpy(), cmap = \"gray\")\n",
    "    axes[i,3].set_title(\"Adv_pred\")\n",
    "    Adv_pred = Adv_pred.cpu()\n",
    "    num_correct = (Adv_pred == target).sum()\n",
    "    num_pixels = torch.numel(target)\n",
    "    print((num_correct/num_pixels).item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
